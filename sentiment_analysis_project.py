# -*- coding: utf-8 -*-
"""Sentiment Analysis Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YNiI74hamvcUpaT2Uzw31x1NqWjj6HR6
"""

!cd('/content/drive/MyDrive/Sentiment')

import tensorflow as tf

import tensorflow.keras as keras
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

"""Importing the data files

"""

imdb_reviews=pd.read_csv("/content/drive/MyDrive/Sentiment/imdb_reviews.csv")
test_reviews=pd.read_csv("/content/drive/MyDrive/Sentiment/test_reviews.csv")

imdb_reviews.head()

test_reviews.head()

"""Preprocessing Data"""

word_index=pd.read_csv("/content/drive/MyDrive/Sentiment/word_indexes.csv")

word_index=dict(zip(word_index.Words,word_index.Indexes))

word_index["<PAD>"]=0
word_index["<START"]=1
word_index["<UNK>"]=2
word_index["<UNUSED>"]=3

print(word_index)

def review_encoder(text):
  arr=[word_index[word] for word in text]
  return arr

train_data,train_labels=imdb_reviews['Reviews'],imdb_reviews['Sentiment']
test_data, test_labels=test_reviews['Reviews'],test_reviews['Sentiment']

print(train_data)

print(word_index)

train_data=train_data.apply(lambda review:review.split())
test_data=test_data.apply(lambda review:review.split())

print(train_data)

train_data=train_data.apply(review_encoder)
test_data=test_data.apply(review_encoder)

print(train_data)

def encode_sentiments(x):
  if x=='positive':
    return 1
  else:
    return 0


train_labels=train_labels.apply(encode_sentiments)
test_labels=test_labels.apply(encode_sentiments)

print(train_labels)

train_data=keras.preprocessing.sequence.pad_sequences(train_data,value=word_index["<PAD>"],padding='post',maxlen=500)
test_data=keras.preprocessing.sequence.pad_sequences(test_data,value=word_index["<PAD>"],padding='post',maxlen=500)

print(train_data)

"""BUILDING MODEL

"""

model=keras.Sequential([keras.layers.Embedding(10000,16,input_length=500),
                        keras.layers.GlobalAveragePooling1D(),
                        keras.layers.Dense(16,activation='relu'),
                        keras.layers.Dense(1,activation='sigmoid')])

model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])

history=model.fit(train_data,train_labels,epochs=30,batch_size=512,validation_data=(test_data,test_labels))

loss,accuracy=model.evaluate(test_data,test_labels)

"""Now we are going to take a random review from our test datadet and check whrther our model produces correct output or not

"""

index=np.random.randint(1,1000)
user_review=test_reviews.loc[index]
print(user_review)